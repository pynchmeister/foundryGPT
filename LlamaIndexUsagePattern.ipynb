{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# 1. Load in Documents\nThe first step is to load in data. The data is represented in the form of ```Document``` objects. We provide a variety of [data loaders](https://gpt-index.readthedocs.io/en/latest/how_to/data_connectors.html) which will load in Documents through the ```load_data``` function, e.g.: ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from llama_index import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader('data').load_data()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "You can also choose to construct documents manually. LlamaIndex exposes the ```Document``` struct.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from llama_index import Document\n\ntext_list = [text1, text2, ...]\ndocuments = [Document(t) for t in text_list]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "A Document represents a lightweight container around the data source. You can now choose to proceed with one of the following steps: \n\n1. Feed the Document object directly into the index\n2. First convert the Document into Node objects\n\n# 2. Parse the Documents into Nodes\nThe next step is to parse these Document objects into Node objects. Nodes represent \"chunks\" of source Documents, whether that is a text chunk, an image, or more. They also contain metadata and relationship information with other nodes and index structures. \nNodes are a first-class citizen in LLamaIndex. You can choose to define Nodes and all its attributes directly. You may also choose to \"parse\" source Documents into Nodes through our ```NodeParser``` classes.\nFor instance, you can do",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from llama_index.node_parser import SimpleNodeParser\n\nparser = SimpleNodeParser()\n\nnodes = parser.get_nodes_from_documents(documents)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "You can also choose to construct Node objects manually and skip the first section. For instance,",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from llama_index.data_structs.node import Node, DocumentRelationship\n\nnode1 = Node(text=\"<text_chunk>\", doc_id=\"<node_id>\")\nnode2 = Node(text=\"<text_chunk>\", doc_id=\"<node_id>\")\n# set relationships\nnode1.relationships[DocumentRelationship.NEXT] = node2.get_doc_id()\nnode2.relationships[DocumentRelationship.PREVIOUS] = node1.get_doc_id()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Index Construction\nhttps://gpt-index.readthedocs.io/en/latest/guides/primer/usage_pattern.html",
      "metadata": {}
    }
  ]
}